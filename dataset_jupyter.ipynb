{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f7d8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math\n",
    "from dipy.io.image import load_nifti\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "import data.utils_dataloader as utils\n",
    "from itertools import islice\n",
    "import h5py\n",
    "import os\n",
    "import torchio as tio\n",
    "from itertools import permutations \n",
    "\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "loaded = {}\n",
    "loaded_gt ={}\n",
    "path,tot = \"\",\"\"\n",
    "\n",
    "def load_path(base_dir,ids):\n",
    "    base_dir_7t = [base_dir + \"/HCP_7T/\" + i   for i in ids]\n",
    "    base_dir_3t = [base_dir + \"/HCP_3T/\" + i   for i in ids]\n",
    "    path_7t = {}\n",
    "    path_3t = {}\n",
    "    for i in base_dir_7t:\n",
    "        path_7t[i[-6:]] = {\"h5\" : i + \"/\" + i[-6:] + \".h5\"\n",
    "                        , \"GT\" : i + \"/\" + i[-6:] + \"_GT.h5\",\n",
    "                        \"bvals\" : i + \"/T1w/Diffusion_7T/bvals\" , \"bvecs\" : i + \"/T1w/Diffusion_7T/bvecs\"}\n",
    "    for i in base_dir_3t:\n",
    "        path_3t[i[-6:]] = {\"h5\" : i + \"/\" + i[-6:] + \".h5\"\n",
    "                        , \"GT\" : i + \"/\" + i[-6:] + \"_GT.h5\",\n",
    "                        \"bvals\" : i + \"/T1w/Diffusion/bvals\" , \"bvecs\" : i + \"/T1w/Diffusion/bvecs\"}\n",
    "    path = {'3T': path_3t, \"7T\":  path_7t}\n",
    "    p = list(path_7t.keys())\n",
    "    q = list(path_3t.keys())\n",
    "    common = list(set(p) & set(q))\n",
    "\n",
    "    return path,len(common)\n",
    "\n",
    "def load_data(base_dir,ids):\n",
    "    ids.sort()\n",
    "    path,tot = load_path(base_dir,ids)\n",
    "    act_ids = []\n",
    "    for i in ids:\n",
    "        name = path['3T'][i]['h5']\n",
    "        if(not os.path.isfile(name)):\n",
    "            continue\n",
    "        res_vol = h5py.File(name, 'r')\n",
    "        \n",
    "        name = path['3T'][i]['GT']\n",
    "        res = h5py.File(name, 'r')\n",
    "        \n",
    "        loaded[i] = {'vol0':res_vol.get('volumes0')[:]\n",
    "                            ,'mask':res_vol.get('mask')[:],\n",
    "                    'ADC':res.get('ADC')[:],\n",
    "                    'FA':res.get('FA')[:] ,\n",
    "                    'color_FA':res.get('color_FA')[:],\n",
    "                    'bvals':res_vol.get('bvals0')[:],\n",
    "                    'bvecs':res_vol.get('bvecs0')[:]}\n",
    "        \n",
    "        name = path['7T'][i]['GT']\n",
    "        \n",
    "        if(not os.path.isfile(name)):\n",
    "            continue\n",
    "        res = h5py.File(name, 'r')\n",
    "        # print(res.keys())\n",
    "        loaded_gt[i] = {'ADC':res.get('ADC')[:]\n",
    "                            ,'FA':res.get('FA')[:] \n",
    "                            ,'color_FA':res.get('color_FA')[:] }\n",
    "        \n",
    "        \n",
    "        res_vol.close()\n",
    "        res.close()\n",
    "\n",
    "        name = path['7T'][i]['h5']\n",
    "        \n",
    "        if(not os.path.isfile(name)):\n",
    "            continue\n",
    "        res = h5py.File(name, 'r')\n",
    "        loaded_gt[i]['vol0'] = res.get('volumes0')[:]\n",
    "        loaded_gt[i]['mask'] = res.get('mask')[:]\n",
    "        res_vol.close()\n",
    "        res.close()\n",
    "        act_ids.append(i)\n",
    "    return act_ids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def interpolate(data,size):\n",
    "#     print(data.shape)\n",
    "    if(len(data.shape)==3):\n",
    "        inp = torch.unsqueeze(data, 0)\n",
    "#         print(inp.shape)\n",
    "    else:\n",
    "        inp = torch.permute(data, (3,0,1,2))\n",
    "    inp = torch.unsqueeze(inp, 0)\n",
    "    interpolated = torch.nn.functional.interpolate(inp,size = torch.Size(size))\n",
    "    interpolated = torch.permute(interpolated, (2,3,4,1,0))\n",
    "    \n",
    "    if(len(data.shape)==3):\n",
    "        interpolated = torch.squeeze(interpolated)\n",
    "    return torch.squeeze(interpolated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f233f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hcp_data(torch.utils.data.Dataset):\n",
    "    def __init__(self, opt,ids,test=False,start_var = False):\n",
    "        super(hcp_data).__init__()\n",
    "        self.blk_size = opt.block_size\n",
    "        self.var_blk_size = start_var\n",
    "        self.cnt = 0\n",
    "        self.thres = opt.thres\n",
    "        self.base_dir = opt.dir if opt.dir != None else \"/storage/users/arihant\"\n",
    "        self.ids = ids\n",
    "        self.debug = opt.debug\n",
    "        self.enable_thres = opt.enable_thres\n",
    "        self.model_type = opt.model_type\n",
    "        self.transform = tio.transforms.RescaleIntensity(masking_method=lambda x: x > 0)\n",
    "        self.batch_size = batch_size\n",
    "        self.scale_const = None\n",
    "        \n",
    "        if(opt.sort == True):\n",
    "            self.ids.sort()\n",
    "            \n",
    "        self.test = test\n",
    "        \n",
    "        self.preload_data()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.blk_indx[-1]\n",
    "        \n",
    "    def __getitem__(self,indx):\n",
    "\n",
    "        blk_idx = np.searchsorted(self.blk_indx, indx)\n",
    "        vol_idx = self.ids[blk_idx]\n",
    "        if(blk_idx == 0):\n",
    "            blk_idx = indx\n",
    "        else:\n",
    "            blk_idx = indx - self.blk_indx[blk_idx-1] - 1\n",
    "        \n",
    "#         print(vol_idx,blk_idx)\n",
    "        if(self.debug):\n",
    "            return self.collate(vol_idx,blk_idx),(self.blks_ret_lr[vol_idx][blk_idx],self.blks_ret_hr[vol_idx][blk_idx])\n",
    "        else:    \n",
    "            return self.collate(vol_idx,blk_idx)\n",
    "        \n",
    "\n",
    "    def collate(self,vol_idx,blk_idx,test = False):\n",
    "        \n",
    "        data = self.loaded_blk[vol_idx][blk_idx],self.loaded_adc[vol_idx][blk_idx],self.loaded_fa[vol_idx][blk_idx],self.loaded_rgb[vol_idx][blk_idx]\n",
    "        \n",
    "        inp = torch.from_numpy(np.stack(data[0]))\n",
    "        if (self.model_type == '2d'):\n",
    "            dims = 3\n",
    "        else:\n",
    "            dims = 4\n",
    "            \n",
    "        hr = np.concatenate([np.expand_dims(data[1],axis = dims),np.expand_dims(data[2],axis = dims),data[3]], axis = dims)\n",
    "        \n",
    "        if(test):\n",
    "            data = self.loaded_adc_lr[vol_idx][blk_idx],self.loaded_fa_lr[vol_idx][blk_idx],self.loaded_rgb_lr[vol_idx][blk_idx]\n",
    "            out = np.concatenate([np.expand_dims(data[1],axis = dims),np.expand_dims(data[2],axis = dims),data[3]], axis = dims)\n",
    "            return inp,hr,self.scale[vol_idx],out,(loaded[vol_idx]['bvals'],loaded[vol_idx]['bvecs']),vol_idx\n",
    "        else:\n",
    "            return inp,hr,self.scale[vol_idx],(loaded[vol_idx]['bvals'],loaded[vol_idx]['bvecs']),vol_idx\n",
    "        \n",
    "    def preload_data(self,blk_size = None,scale = None,var = None,test = None):\n",
    "        \n",
    "        \n",
    "        if blk_size is not None:\n",
    "            self.blk_size = blk_size\n",
    "            \n",
    "        if scale is not None:\n",
    "            self.scale_const = scale \n",
    "            \n",
    "        if var is not None:\n",
    "            self.var_blk_size = var\n",
    "            \n",
    "        if test is not None:\n",
    "            self.test = True\n",
    "            \n",
    "        self.blk_indx = []\n",
    "        self.loaded_blk = {}\n",
    "        self.loaded_adc = {}\n",
    "        self.loaded_fa = {}\n",
    "        self.loaded_rgb = {}\n",
    "        self.scale = {}\n",
    "        self.blks_ret_lr = {}\n",
    "        self.blks_ret_hr = {}\n",
    "        if(self.test):\n",
    "            self.loaded_adc_lr = {}\n",
    "            self.loaded_fa_lr = {}\n",
    "            self.loaded_rgb_lr = {}\n",
    "                \n",
    "        for i in self.ids:\n",
    "            if(self.test):\n",
    "                self.loaded_blk[i],self.loaded_adc[i],self.loaded_fa[i],self.loaded_rgb[i],self.scale[i],self.blks_ret_lr[i],self.blks_ret_hr[i],self.loaded_adc_lr[i],self.loaded_fa_lr[i],self.loaded_rgb_lr[i] = self.pre_proc(i)\n",
    "            else:\n",
    "                self.loaded_blk[i],self.loaded_adc[i],self.loaded_fa[i],self.loaded_rgb[i],self.scale[i],self.blks_ret_lr[i],self.blks_ret_hr[i] = self.pre_proc(i)\n",
    "            if(self.debug == True):\n",
    "                print(i,\"loaded\")\n",
    "        self.blk_indx = np.cumsum(self.blk_indx)\n",
    "\n",
    "    \n",
    "    def blk_points_pair(self,datalr,datahr,blk_size = [16,16,4],stride = (0,0,0),scale = (1,1,1)):\n",
    "    \n",
    "        shpind = torch.nonzero(datalr)\n",
    "        xmin,xmax = torch.min(shpind[:,0]).item(),torch.max(shpind[:,0]).item()\n",
    "        ymin,ymax = torch.min(shpind[:,1]).item(),torch.max(shpind[:,1]).item()\n",
    "        zmin,zmax = torch.min(shpind[:,1]).item(),torch.max(shpind[:,2]).item()\n",
    "\n",
    "        lr_start = [xmin,ymin,zmin]\n",
    "        lr_end = [xmax - blk_size[0] + 1,ymax - blk_size[1] + 1,zmax - blk_size[2] + 1]\n",
    "\n",
    "        shpind = torch.nonzero(datahr)\n",
    "        xmin,xmax = torch.min(shpind[:,0]).item(),torch.max(shpind[:,0]).item()\n",
    "        ymin,ymax = torch.min(shpind[:,1]).item(),torch.max(shpind[:,1]).item()\n",
    "        zmin,zmax = torch.min(shpind[:,1]).item(),torch.max(shpind[:,2]).item()\n",
    "\n",
    "        blk_size_hr = [round(blk_size[i]*scale[i]) for i in range(3)]\n",
    "        hr_start = [xmin,ymin,zmin]\n",
    "        hr_end = [xmax - blk_size_hr[0] + 1,ymax - blk_size_hr[1] + 1,zmax - blk_size_hr[2] + 1]\n",
    "\n",
    "        a,b = [lr_end[i] - lr_start[i] for i in range(3)],[hr_end[i] - hr_start[i] for i in range(3)]\n",
    "        offset = [round(b[i]/a[i],1) for i in range(3)]\n",
    "        ranges_lr = [np.arange(lr_start[i], lr_end[i], blk_size[i] - stride[i]) for i in range(3)]\n",
    "        ranges_hr = [np.round(ranges_lr[i]*offset[i]) for i in range(3)]\n",
    "        \n",
    "        # misc = {'offset': offset,\n",
    "        #         'hr_pts': (hr_start,hr_end)}\n",
    "        \n",
    "        ind_block_lr = []\n",
    "        ind_block_hr = []\n",
    "        count = 0\n",
    "\n",
    "        for ii in np.arange(0, ranges_lr[0].shape[0]):\n",
    "            for jj in np.arange(0, ranges_lr[1].shape[0]):\n",
    "                for kk in np.arange(0, ranges_lr[2].shape[0]):\n",
    "                    x,y,z = ranges_lr[0][ii],ranges_lr[1][jj],ranges_lr[2][kk]\n",
    "                    temp_lr = np.array([x, x + blk_size[0]-1, \n",
    "                                        y, y + blk_size[1]-1, \n",
    "                                        z, z + blk_size[2]-1]).astype(int)\n",
    "                    \n",
    "                    x,y,z = ranges_hr[0][ii],ranges_hr[1][jj],ranges_hr[2][kk]\n",
    "                    temp_hr = np.array([x, x + blk_size_hr[0]-1,\n",
    "                                        y, y + blk_size_hr[1]-1,\n",
    "                                        z, z + blk_size_hr[2]-1]).astype(int)\n",
    "                    \n",
    "                    \n",
    "                    curr_blk = datalr[temp_lr[0]:temp_lr[1]+1, temp_lr[2]:temp_lr[3]+1, temp_lr[4]:temp_lr[5]+1, ...]\n",
    "                    curr_blk_hr = datahr[temp_hr[0]:temp_hr[1]+1, temp_hr[2]:temp_hr[3]+1, temp_hr[4]:temp_hr[5]+1, ...]\n",
    "#                     print(curr_blk.size(),curr_blk.shape,curr_blk_hr.shape,curr_blk_hr.size())\n",
    "\n",
    "                    if(self.enable_thres):\n",
    "                        if((torch.numel(curr_blk) != 0 and torch.count_nonzero(curr_blk)/torch.numel(curr_blk) > self.thres) and \n",
    "                        (torch.numel(curr_blk_hr) != 0 and torch.count_nonzero(curr_blk_hr)/torch.numel(curr_blk_hr) > self.thres)):\n",
    "                            ind_block_lr.append(temp_lr)\n",
    "                            ind_block_hr.append(temp_hr)\n",
    "                            count = count + 1\n",
    "                    else:\n",
    "                        ind_block_lr.append(temp_lr)\n",
    "                        ind_block_hr.append(temp_hr)\n",
    "                        count = count + 1\n",
    "                    \n",
    "        ind_block_lr = np.stack(ind_block_lr)\n",
    "        ind_block_lr = ind_block_lr.astype(int)\n",
    "        ind_block_hr = np.stack(ind_block_hr)\n",
    "        ind_block_hr = ind_block_hr.astype(int)\n",
    "        \n",
    "        return ind_block_lr,ind_block_hr,len(ind_block_lr)\n",
    "\n",
    "\n",
    "    def extract_block(self,data, inds):\n",
    "            blocks = []\n",
    "            for ii in np.arange(inds.shape[0]):\n",
    "                inds_this = inds[ii, :]\n",
    "                curr_blk = data[inds_this[0]:inds_this[1]+1, inds_this[2]:inds_this[3]+1, inds_this[4]:inds_this[5]+1, ...]\n",
    "                blocks.append(curr_blk.squeeze())\n",
    "            return torch.from_numpy(np.stack(blocks, axis=0))\n",
    "\n",
    "    def norm(self,data):\n",
    "        if(len(data.size())<4):\n",
    "            temp = self.transform(torch.unsqueeze(data,0))\n",
    "            return torch.squeeze(temp)\n",
    "        return self.transform(data)\n",
    "    \n",
    "    def pre_proc(self,idx):\n",
    "\n",
    "        vol = torch.from_numpy(loaded[idx]['vol0'])\n",
    "        \n",
    "        if self.var_blk_size:\n",
    "            x = np.around(np.random.uniform(1.2,2),decimals=1)\n",
    "            asy = 0.1\n",
    "            curr_scale = np.around(np.random.uniform(x-asy,x+asy,3),decimals=1)\n",
    "            if(self.model_type == '2d'):\n",
    "                curr_blk_size = [1,np.random.randint(20,50),np.random.randint(20,50)]\n",
    "            else:    \n",
    "                curr_blk_size = [np.random.randint(2,8),np.random.randint(20,50),np.random.randint(20,50)]\n",
    "            \n",
    "            curr_blk_size = list(set(permutations(curr_blk_size)))[np.random.randint(0,3)]\n",
    "            \n",
    "            if(self.debug):\n",
    "                print(idx,curr_blk_size)\n",
    "            \n",
    "        else:\n",
    "            if self.scale_const is None:\n",
    "                x = np.around(np.random.uniform(1.2,2),decimals=1)\n",
    "                asy = 0.1\n",
    "                curr_scale = np.around(np.random.uniform(x-asy,x+asy,3),decimals=1)\n",
    "            else:\n",
    "                curr_scale = self.scale_const\n",
    "                \n",
    "            curr_blk_size = list(set(permutations(self.blk_size)))[self.cnt]\n",
    "            \n",
    "            self.cnt+=1\n",
    "            if(self.cnt>2):\n",
    "                self.cnt = 0\n",
    "        \n",
    "        if(min(curr_blk_size) == 1):\n",
    "            curr_scale[np.where(np.asarray(curr_blk_size) == 1)[0][0]] = 1\n",
    "    \n",
    "        size = [int(curr_scale[i] * vol.shape[i]) for i in range(3)]\n",
    "        \n",
    "        # print(curr_blk_size,curr_scale)\n",
    "        vol_hr = interpolate(torch.from_numpy(loaded_gt[idx]['vol0']),size)\n",
    "        adc = interpolate(torch.from_numpy(loaded_gt[idx]['ADC']),size)\n",
    "        fa = interpolate(torch.from_numpy(loaded_gt[idx]['FA']),size)\n",
    "        rgb = interpolate(torch.from_numpy(loaded_gt[idx]['color_FA']),size)\n",
    "\n",
    "        curr_blk = self.blk_points_pair(vol,vol_hr,blk_size=curr_blk_size,scale=curr_scale)\n",
    "        if(not self.debug):\n",
    "            curr_scale = curr_scale[curr_scale>1]\n",
    "        \n",
    "        drop_last = (curr_blk[2]//self.batch_size)*self.batch_size\n",
    "        \n",
    "        \n",
    "        blks_img = torch.split(self.extract_block(vol,curr_blk[0])[:drop_last,...],self.batch_size)\n",
    "        blks_adc = torch.split(self.extract_block(adc,curr_blk[1])[:drop_last,...],self.batch_size)\n",
    "        blks_fa = torch.split(self.extract_block(fa,curr_blk[1])[:drop_last,...],self.batch_size)\n",
    "        blks_rgb = torch.split(self.extract_block(rgb,curr_blk[1])[:drop_last,...],self.batch_size)\n",
    "        print(len(blks_rgb))\n",
    "        curr_blk_lr = torch.split(torch.from_numpy(curr_blk[0])[:drop_last,...],self.batch_size)\n",
    "        curr_blk_hr = torch.split(torch.from_numpy(curr_blk[1])[:drop_last,...],self.batch_size)\n",
    "        \n",
    "        self.blk_indx.append((curr_blk[2]//self.batch_size)-1)\n",
    "        \n",
    "#         print(blks_rgb.shape)\n",
    "        \n",
    "        if(self.test):\n",
    "            blks_lr_adc = torch.split(self.extract_block(torch.from_numpy(loaded[idx]['ADC']),curr_blk[0])[:drop_last,...],self.batch_size)\n",
    "            blks_lr_fa = torch.split(self.extract_block(torch.from_numpy(loaded[idx]['FA']),curr_blk[0])[:drop_last,...],self.batch_size)\n",
    "            blks_lr_rgb = torch.split(self.extract_block(torch.from_numpy(loaded[idx]['color_FA']),curr_blk[0])[:drop_last,...],self.batch_size)\n",
    "            # print(blks_lr_adc.shape,blks_lr_fa.shape,blks_lr_rgb.shape)\n",
    "            return blks_img,blks_adc,blks_fa,blks_rgb,curr_scale,curr_blk_lr,curr_blk_hr,blks_lr_adc,blks_lr_fa,blks_lr_rgb\n",
    "    \n",
    "        return blks_img,blks_adc,blks_fa,blks_rgb,curr_scale,curr_blk_lr,curr_blk_hr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cd433637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmri_arb3d,16_batch,20_vols,20_test,blk_(32, 32, 4),loss_1*MSE,opt_ADAM,var_True,jupyternotebook\n"
     ]
    }
   ],
   "source": [
    "from option import args\n",
    "import torch\n",
    "import utility\n",
    "import data\n",
    "import utils\n",
    "import model\n",
    "import loss\n",
    "from trainer import Trainer\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "args.run_name = \"jupyternotebook\"\n",
    "ids = utils.get_ids()\n",
    "ids.sort()\n",
    "total_vols = args.no_vols+args.test_vols\n",
    "temp = ids[:total_vols]\n",
    "ids = temp\n",
    "if(args.model_type == '2d'):\n",
    "    args.block_size = (32,32,1)\n",
    "\n",
    "if (args.run_name == '..'):\n",
    "    args.run_name = f\"{args.model}{args.model_type},{args.batch_size}_batch,{args.no_vols}_vols,{args.test_vols}_test,blk_{args.block_size},loss_{args.loss},opt_{args.optimizer},var_{args.var_blk_size}\"\n",
    "else:\n",
    "    args.run_name = f\"{args.model}{args.model_type},{args.batch_size}_batch,{args.no_vols}_vols,{args.test_vols}_test,blk_{args.block_size},loss_{args.loss},opt_{args.optimizer},var_{args.var_blk_size},{args.run_name}\"\n",
    "print(args.run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "68a584fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data(args.dir,ids[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "61bc9997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "tm = hcp_data(args,ids[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "795be2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 22])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.blk_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "238aab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "ch = DataLoader(dataset=tm, batch_size=1, drop_last=True,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d3114df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6277cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = next(iter(ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a7bcedc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 4, 32, 7])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fde5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
