{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23eb4453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of common Subjects  171\n"
     ]
    }
   ],
   "source": [
    "from option import args\n",
    "import torch\n",
    "import utility\n",
    "import data\n",
    "import utils\n",
    "import model\n",
    "import loss\n",
    "from trainer import Trainer\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08611ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.no_vols = 2\n",
    "args.test_vols = 2\n",
    "np.random.seed(args.seed)\n",
    "ids = utils.get_ids()\n",
    "# ids.sort()\n",
    "total_vols = args.no_vols+args.test_vols\n",
    "ids.sort()\n",
    "ids = ids[:total_vols]\n",
    "ids = np.random.choice(ids,total_vols,replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00d2f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['104416', '102816', '100610', '102311'], dtype='<U6')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b61b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Done\n"
     ]
    }
   ],
   "source": [
    "loader = data.Data(args,ids= ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f996306",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (lr,hr,scale,tv) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader\u001b[38;5;241m.\u001b[39mtraining_data):\n\u001b[0;32m----> 2\u001b[0m     lr_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# ranges from [0, 1]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     hr_tensor \u001b[38;5;241m=\u001b[39m hr\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# ranges from [0, 1]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     tv_tensor \u001b[38;5;241m=\u001b[39m tv\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# ranges from [0, 1]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "for batch, (lr,hr,scale,tv) in enumerate(loader.training_data):\n",
    "    lr_tensor = lr.squeeze().to('cuda').float()  # ranges from [0, 1]\n",
    "    hr_tensor = hr.squeeze().to('cuda').float()  # ranges from [0, 1]\n",
    "    tv_tensor = tv.squeeze().to('cuda').float()  # ranges from [0, 1]\n",
    "    # print(lr_tensor.shape,hr_tensor.shape,scale)\n",
    "    scale = np.asarray(scale[0,:])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38e48ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " (torch.Size([1, 16, 32, 4, 32, 7]),\n",
       "  torch.Size([1, 16, 38, 4, 35, 5]),\n",
       "  tensor([[1.2000, 1.1000, 1.1000]], dtype=torch.float64),\n",
       "  torch.Size([1, 16, 38, 4, 35, 6])))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, (lr.shape,hr.shape,scale,tv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d4363c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " (torch.Size([16, 32, 32, 4, 7]),\n",
       "  torch.Size([16, 42, 42, 5, 5]),\n",
       "  tensor([[1.2000, 1.1000, 1.1000]], dtype=torch.float64),\n",
       "  torch.Size([16, 42, 42, 5, 6])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, (lr_tensor.shape,hr_tensor.shape,scale,tv_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6268acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05404305, 0.05469534, 0.055117  , ..., 0.36352447, 0.36451533,\n",
       "       0.39078027], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tv_tensor.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77795423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.viz import window, actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842ec1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
