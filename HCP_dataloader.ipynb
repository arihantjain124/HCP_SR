{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6994d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86989a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of common Subjects  171\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "def blocks(mask):\n",
    "    tmp = np.nonzero(mask);\n",
    "    xind = tmp[0] * 1.0;\n",
    "    yind = tmp[1] * 1.0;\n",
    "    zind = tmp[2] * 1.0;\n",
    "\n",
    "    xmin = np.min(xind); xmax = np.max(xind);\n",
    "    ymin = np.min(yind); ymax = np.max(yind);\n",
    "    zmin = np.min(zind); zmax = np.max(zind);\n",
    "    ind_brain = [xmin, xmax, ymin, ymax, zmin, zmax]; \n",
    "\n",
    "    # calculate number of blocks along each dimension\n",
    "    sz_block = 64\n",
    "    xlen = xmax - xmin + 1;\n",
    "    ylen = ymax - ymin + 1;\n",
    "    zlen = zmax - zmin + 1;\n",
    "\n",
    "    nx = int(np.ceil(xlen / sz_block));\n",
    "    ny = int(np.ceil(ylen / sz_block));\n",
    "    nz = int(np.ceil(zlen / sz_block));\n",
    "\n",
    "    # determine starting and ending indices of each block\n",
    "    xstart = xmin;\n",
    "    ystart = ymin;\n",
    "    zstart = zmin;\n",
    "\n",
    "    xend = xmax - sz_block + 1;\n",
    "    yend = ymax - sz_block + 1;\n",
    "    zend = zmax - sz_block + 1;\n",
    "\n",
    "    xind_block = np.round(np.linspace(xstart, xend, nx));\n",
    "    yind_block = np.round(np.linspace(ystart, yend, ny));\n",
    "    zind_block = np.round(np.linspace(zstart, zend, nz));\n",
    "\n",
    "    ind_block = np.zeros([xind_block.shape[0]*yind_block.shape[0]*zind_block.shape[0], 6])\n",
    "    count = 0\n",
    "    for ii in np.arange(0, xind_block.shape[0]):\n",
    "        for jj in np.arange(0, yind_block.shape[0]):\n",
    "            for kk in np.arange(0, zind_block.shape[0]):\n",
    "                ind_block[count, :] = np.array([xind_block[ii], xind_block[ii]+sz_block-1, yind_block[jj], yind_block[jj]+sz_block-1, zind_block[kk], zind_block[kk]+sz_block-1])\n",
    "                count = count + 1\n",
    "\n",
    "    ind_block = ind_block.astype(int);\n",
    "    return ind_block\n",
    "\n",
    "def dataloader_plotter(gt,pred,data_id,channel,offset):\n",
    "    data,mask,scan,gtab,grad = utils.load_hcp(data_id,'3T',crop = 30)\n",
    "    temp_gt = np.zeros((mask.shape))\n",
    "    temp_pred = np.zeros((mask.shape))\n",
    "    ind = blocks(mask)\n",
    "    offset = offset * 12\n",
    "    gt = gt[offset*12:(offset+1)*12,...]\n",
    "    pred = pred[offset*12:(offset+1)*12,...]\n",
    "    for ii in np.arange(ind.shape[0]):\n",
    "        inds_this = ind[ii, :]\n",
    "        temp_pred[inds_this[0]:inds_this[1]+1, inds_this[2]:inds_this[3]+1, inds_this[4]:inds_this[5]+1] = pred[ii,:,:,:,channel]\n",
    "        temp_gt[inds_this[0]:inds_this[1]+1, inds_this[2]:inds_this[3]+1, inds_this[4]:inds_this[5]+1] = gt[ii,:,:,:,channel]\n",
    "    return temp_gt,temp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06fc2873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--sort'], dest='sort', nargs=None, const=None, default=None, type=<class 'bool'>, choices=None, required=False, help='dataset_directory', metavar=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"IMDN\")\n",
    "parser.add_argument(\"--block_size\", type=int, default=64,\n",
    "                    help=\"Block Size\")\n",
    "parser.add_argument(\"--crop_depth\", type=int, default=30,\n",
    "                    help=\"crop across z-axis\")\n",
    "parser.add_argument(\"--dir\", type=str,\n",
    "                    help=\"dataset_directory\")\n",
    "parser.add_argument(\"--batch_size\", type=int,\n",
    "                    help=\"dataset_directory\")\n",
    "parser.add_argument(\"--sort\", type=bool,\n",
    "                    help=\"dataset_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c13f4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = list(parser.parse_known_args())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f0b4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dir = \"/storage/users/arihant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eeac014",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01591493",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.sort = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "353fda07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(block_size=64, crop_depth=30, dir='/storage/users/arihant', batch_size=4, sort=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b83b0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.HCP_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfce84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "ids = utils.get_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae9da75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = data.HCP_dataset.hcp_data(args,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03ce80c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "095c1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def worker_init_fn(worker_id):\n",
    "    worker_info = torch.utils.data.get_worker_info()\n",
    "    dataset = worker_info.dataset\n",
    "    tot_len = len(dataset.ids)\n",
    "    per_worker = int(tot_len / float(worker_info.num_workers))\n",
    "    worker_id = worker_info.id\n",
    "    dataset.ids = dataset.ids[worker_id * per_worker:max(((worker_id+1) * per_worker),tot_len )]\n",
    "    dataset.curr_indx_blk = 0\n",
    "\n",
    "    \n",
    "def custom_collate(data):\n",
    "    data = np.stack([data]).squeeze()\n",
    "    data_gt = data[...,:8]\n",
    "    data_pred = data[...,8:]\n",
    "    return data_gt,data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63306c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, num_workers=0,batch_size = 60,worker_init_fn=worker_init_fn,collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64ae9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "100610 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arihant/DWI_SR/HCP_SR/data/utils_dataloader.py:147: RuntimeWarning: invalid value encountered in arccos\n",
      "  ang_error = np.degrees(np.arccos(abs(dsm_rot @ dirs.T)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 64, 64, 64, 8) (60, 64, 64, 64, 7)\n",
      "0\n",
      "102311 1\n",
      "(60, 64, 64, 64, 8) (60, 64, 64, 64, 7)\n",
      "1\n",
      "102816 2\n",
      "(60, 64, 64, 64, 8) (60, 64, 64, 64, 7)\n",
      "2\n",
      "104416 3\n",
      "(60, 64, 64, 64, 8) (60, 64, 64, 64, 7)\n",
      "3\n",
      "105923 4\n",
      "(60, 64, 64, 64, 8) (60, 64, 64, 64, 7)\n",
      "4\n",
      "108323 5\n",
      "(60, 64, 64, 64, 8) (60, 64, 64, 64, 7)\n",
      "5\n",
      "109123 6\n",
      "(60, 64, 64, 64, 8) (60, 64, 64, 64, 7)\n",
      "6\n",
      "111312 7\n",
      "(60, 64, 64, 64, 8) (60, 64, 64, 64, 7)\n",
      "59.7 s ± 4.3 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(1):\n",
    "    data = iter(training_dataloader)\n",
    "    for j in data:\n",
    "        print(j[0].shape,j[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt,pred = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_gt,plt_pred = dataloader_plotter(gt,pred,'100610',2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_gt.shape,plt_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=25\n",
    "f, axis = plt.subplots(1, 3)\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "im = axis[0].imshow(plt_pred[:,:,i], cmap='gray')\n",
    "plt.colorbar(im, ax=axis[0],shrink = 0.4)\n",
    "im = axis[1].imshow(plt_gt[:,:,i], cmap='gray')\n",
    "plt.colorbar(im, ax=axis[1],shrink = 0.4)\n",
    "im = axis[2].imshow(plt_gt[:,:,i] - plt_pred[:,:,i], clim=(-1., 1.), cmap='bwr')\n",
    "plt.colorbar(im, ax=axis[2],shrink = 0.4)\n",
    "# im = ax[i, j].imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ed05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda9195",
   "metadata": {},
   "source": [
    "### Pytorch Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475292b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt,pred = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4cf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084022a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.from_numpy(pred).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.permute(pred, (0,4,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531bf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72480df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_in = nn.Sequential(\n",
    "#             nn.Conv3d(7, 128, 3,padding=\"same\"),      \n",
    "#             nn.ReLU()\n",
    "# )\n",
    "# model_mid = nn.Sequential(\n",
    "#             nn.Conv3d(128, 128, 3,padding=\"same\"),     \n",
    "#             nn.BatchNorm3d(128),    \n",
    "#             nn.ReLU()\n",
    "# )\n",
    "# model_out = nn.Sequential(\n",
    "#             nn.Conv3d(128, 7, 3,padding=\"same\"),  \n",
    "#             nn.ReLU()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb67ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model_in(pred)\n",
    "# for i in range(8):\n",
    "#     output = model_mid(output)\n",
    "# output = model_out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057872fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchcnn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3740c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dti = torchcnn.DeepDTI_torch().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b3e9ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 7.50 GiB (GPU 0; 44.37 GiB total capacity; 7.91 GiB already allocated; 1.45 GiB free; 7.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %%timeit\u001b[39;00m\n\u001b[1;32m      2\u001b[0m temp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_dti\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DWI_SR/HCP_SR/torchcnn.py:24\u001b[0m, in \u001b[0;36mDeepDTI_torch.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Set 1\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m     26\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_mid(output)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/activation.py:102\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.50 GiB (GPU 0; 44.37 GiB total capacity; 7.91 GiB already allocated; 1.45 GiB free; 7.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "temp = torch.rand((60,7,64,64,64)).cuda()\n",
    "output = model_dti.forward(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae75249e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 7, 64, 64, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bdb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
