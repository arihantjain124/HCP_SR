{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edaf78fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arb_decoder_2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munfoldNd\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSEUnetModel\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marb_decoder_2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImplicitDecoder\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDMRI_RCAN\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,in_chans \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m,int_chans \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'arb_decoder_2d'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import common\n",
    "from argparse import Namespace\n",
    "import random \n",
    "import math\n",
    "from model.rdn import make_rdn\n",
    "from model.resblock import ResBlock\n",
    "import unfoldNd\n",
    "from model.models import CSEUnetModel\n",
    "from arb_decoder_2d import ImplicitDecoder\n",
    "\n",
    "class DMRI_RCAN(nn.Module):\n",
    "    def __init__(self,in_chans = 7,int_chans = 32):\n",
    "        super().__init__()\n",
    "        self.encoder = CSEUnetModel(in_chans=in_chans,out_chans=64,chans=int_chans,num_pool_layers=3,drop_prob = 0,attention_type='cSE',reduction=16)\n",
    "        self.decoder = ImplicitDecoder(in_channels= 64) \n",
    "    \n",
    "    def set_scale(self, scale):\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \n",
    "        B,C,H,W,D = inp.shape\n",
    "        # print(self.scale)\n",
    "        H_hr = round(H*self.scale[0])\n",
    "        W_hr = round(W*self.scale[1])\n",
    "        \n",
    "        size = [H_hr, W_hr]\n",
    "        \n",
    "        feat = self.encoder(inp)\n",
    "        # print(feat.shape)\n",
    "        # latent = self.latent_layer(feat)\n",
    "        \n",
    "        pred = self.decoder(feat,size)\n",
    "        \n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7404567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from option import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1763f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from model.models import CSEUnetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc696e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CSEUnetModel(in_chans=7,out_chans=64,chans=32,num_pool_layers=3,drop_prob = 0,attention_type='cSE',reduction=16)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c45e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSEUnetModel(\n",
       "  (down_sample_layers): ModuleList(\n",
       "    (0): ConvBlock(in_chans=7, out_chans=32, drop_prob=0)\n",
       "    (1): ConvBlock(in_chans=32, out_chans=64, drop_prob=0)\n",
       "    (2): ConvBlock(in_chans=64, out_chans=128, drop_prob=0)\n",
       "  )\n",
       "  (conv): ConvBlock(in_chans=128, out_chans=128, drop_prob=0)\n",
       "  (up_sample_layers): ModuleList(\n",
       "    (0): ConvBlock(in_chans=256, out_chans=64, drop_prob=0)\n",
       "    (1): ConvBlock(in_chans=128, out_chans=32, drop_prob=0)\n",
       "    (2): ConvBlock(in_chans=64, out_chans=32, drop_prob=0)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27b942d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = torch.rand((1,7,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd89b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = encoder(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f59ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56131a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = ImplicitDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29938dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (45,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c67f341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImplicitDecoder(\n",
       "  (K): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): ResBlock(\n",
       "        (convs): Sequential(\n",
       "          (0): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (1): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (2): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (3): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CBAM): CBAM(\n",
       "          (ca): ChannelAttention(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "            (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu1): ReLU()\n",
       "            (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (sa): SpatialAttention(\n",
       "            (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1-4): 4 x Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): ResBlock(\n",
       "        (convs): Sequential(\n",
       "          (0): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (1): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (2): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (3): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CBAM): CBAM(\n",
       "          (ca): ChannelAttention(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "            (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu1): ReLU()\n",
       "            (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (sa): SpatialAttention(\n",
       "            (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Q): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): SineAct()\n",
       "    )\n",
       "    (1-4): 4 x Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): SineAct()\n",
       "    )\n",
       "  )\n",
       "  (last_layer): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (in_branch): Sequential(\n",
       "    (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61e1f7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 45, 45]) torch.Size([1, 576, 45, 45])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 45, 45])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(tmp,size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "425437ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import common\n",
    "from argparse import Namespace\n",
    "import random \n",
    "import math\n",
    "from model.rdn import make_rdn\n",
    "from model.resblock import ResBlock\n",
    "\n",
    "class SineAct(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)\n",
    "\n",
    "def patch_norm_2d(x, kernel_size=3):\n",
    "    mean = F.avg_pool2d(x, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "    mean_sq = F.avg_pool2d(x**2, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "    var = mean_sq - mean**2\n",
    "    return (x-mean)/(var + 1e-6)\n",
    "\n",
    "class ImplicitDecoder(nn.Module):\n",
    "    def __init__(self, in_channels=64, hidden_dims=[64, 64, 64, 64, 64],out_chans= 5):\n",
    "        super().__init__()\n",
    "\n",
    "        last_dim_K = in_channels * 9\n",
    "        \n",
    "        last_dim_Q = 3\n",
    "\n",
    "        self.K = nn.ModuleList()\n",
    "        self.Q = nn.ModuleList()\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            self.K.append(nn.Sequential(nn.Conv2d(last_dim_K, hidden_dim, 1),\n",
    "                                        nn.ReLU(),\n",
    "                                        ResBlock(channels = hidden_dim, nConvLayers = 4)\n",
    "                                        ))    \n",
    "            self.Q.append(nn.Sequential(nn.Conv2d(last_dim_Q, hidden_dim, 1),\n",
    "                                        SineAct()))\n",
    "            last_dim_K = hidden_dim\n",
    "            last_dim_Q = hidden_dim\n",
    "            \n",
    "        self.last_layer = nn.Conv2d(hidden_dims[-1], out_chans, 1)\n",
    "        \n",
    "        self.in_branch = nn.Sequential(nn.Conv2d(in_channels * 9, hidden_dims[-2], 1),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv2d(hidden_dims[-2],hidden_dims[-1], 1),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv2d(hidden_dims[-1],out_chans, 1),\n",
    "                            nn.ReLU())\n",
    "        \n",
    "    def _make_pos_encoding(self, x, size): \n",
    "        B, C, H, W = x.shape\n",
    "        H_up, W_up = size\n",
    "       \n",
    "        h_idx = -1 + 1/H + 2/H * torch.arange(H, device=x.device).float()\n",
    "        w_idx = -1 + 1/W + 2/W * torch.arange(W, device=x.device).float()\n",
    "        in_grid = torch.stack(torch.meshgrid(h_idx, w_idx), dim=0)\n",
    "\n",
    "        h_idx_up = -1 + 1/H_up + 2/H_up * torch.arange(H_up, device=x.device).float()\n",
    "        w_idx_up = -1 + 1/W_up + 2/W_up * torch.arange(W_up, device=x.device).float()\n",
    "        up_grid = torch.stack(torch.meshgrid(h_idx_up, w_idx_up), dim=0)\n",
    "        \n",
    "        rel_grid = (up_grid - F.interpolate(in_grid.unsqueeze(0), size=(H_up, W_up), mode='nearest-exact'))\n",
    "        rel_grid[:,0,:,:] *= H\n",
    "        rel_grid[:,1,:,:] *= W\n",
    "\n",
    "        return rel_grid.contiguous().detach()\n",
    "\n",
    "    def step(self, x, syn_inp):\n",
    "        \n",
    "        q = syn_inp\n",
    "        \n",
    "        k = x\n",
    "        \n",
    "        for i in range(len(self.K)):\n",
    "            \n",
    "            k = self.K[i](k)\n",
    "            q = k*self.Q[i](q)\n",
    "            \n",
    "        q = self.last_layer(q)\n",
    "        \n",
    "        return q + self.in_branch(x)\n",
    "\n",
    "\n",
    "    def forward(self, x, size):\n",
    "        B, C, H_in, W_in = x.shape\n",
    "        \n",
    "        rel_coord = (self._make_pos_encoding(x, size).expand(B, -1, *size))\n",
    "        \n",
    "        ratio = (x.new_tensor([math.sqrt((H_in*W_in)/(size[0]*size[1]))]).view(1, -1, 1, 1).expand(B, -1, *size))\n",
    "        \n",
    "        syn_inp = torch.cat([rel_coord, ratio], dim=1)\n",
    "        \n",
    "        x = F.interpolate(F.unfold(x, 3, padding=1).view(B, C*9, H_in, W_in), size=syn_inp.shape[-2:], mode='bilinear')\n",
    "        \n",
    "        print(syn_inp.shape,x.shape)\n",
    "        pred = self.step(x, syn_inp)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54183bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
