{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d98d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(block_size=(16, 16, 16), test_block_size=(16, 16, 16), crop_depth=15, dir='/storage', batch_size=16, sort=True, debug=False, preload=True, ret_points=False, thres=0.6, offset=10, gaps=20, lr=0.0001, lr_decay=40, decay_type='step', gamma=0.5, optimizer='ADAM', momentum=0.9, beta1=0.9, beta2=0.999, epsilon=1e-08, weight_decay=0, start_epoch=0, loss='1*MSE', skip_threshold=1000000.0, save='DTIArbNet', load='.', save_models=False, resume=0, print_every=200, save_every=30, cpu=False, seed=1, reset=False, pin_mem=False, train_set=0.7, model='dmri_arb', act='relu', pre_train='None', precision='single', cuda=True, scale=(1, 1, 1), epochs=400)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"DTI_ARB\")\n",
    "parser.add_argument(\"--block_size\", type=tuple, default=(16,16,16),\n",
    "                    help=\"Block Size\")\n",
    "parser.add_argument(\"--test_block_size\", type=tuple, default=(16,16,16),\n",
    "                    help=\"Block Size\")\n",
    "parser.add_argument(\"--crop_depth\", type=int, default=15,\n",
    "                    help=\"crop across z-axis\")\n",
    "parser.add_argument(\"--dir\", type=str,\n",
    "                    help=\"dataset_directory\")\n",
    "parser.add_argument(\"--batch_size\", type=int,\n",
    "                    help=\"Batch_size\")\n",
    "parser.add_argument(\"--sort\", type=bool,\n",
    "                    help=\"Sort Subject Ids\")\n",
    "parser.add_argument(\"--debug\", type=bool,\n",
    "                    help=\"Print additional input\")\n",
    "parser.add_argument(\"--preload\", type=bool,\n",
    "                    help=\"Preload data into memory\")\n",
    "parser.add_argument(\"--ret_points\", type=bool, default=False,\n",
    "                    help=\"return box point of crops\")\n",
    "parser.add_argument(\"--thres\", type=float, default=0.6,\n",
    "                    help=\"threshold for blk emptiness\")\n",
    "parser.add_argument(\"--offset\", type=int, default=20,\n",
    "                    help=\"epoch with scale (1,1,1)\")\n",
    "parser.add_argument(\"--gaps\", type=int, default=20,\n",
    "                    help=\"number of epochs of gap between each scale change\")\n",
    "\n",
    "\n",
    "# Optimization specifications\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay', type=int, default=40,\n",
    "                    help='learning rate decay per N epochs')\n",
    "parser.add_argument('--decay_type', type=str, default='step',\n",
    "                    help='learning rate decay type')\n",
    "parser.add_argument('--gamma', type=float, default=0.5,\n",
    "                    help='learning rate decay factor for step decay')\n",
    "parser.add_argument('--optimizer', default='ADAM',\n",
    "                    choices=('SGD', 'ADAM', 'RMSprop'),\n",
    "                    help='optimizer to use (SGD | ADAM | RMSprop)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='SGD momentum')\n",
    "parser.add_argument('--beta1', type=float, default=0.9,\n",
    "                    help='ADAM beta1')\n",
    "parser.add_argument('--beta2', type=float, default=0.999,\n",
    "                    help='ADAM beta2')\n",
    "parser.add_argument('--epsilon', type=float, default=1e-8,\n",
    "                    help='ADAM epsilon for numerical stability')\n",
    "parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                    help='weight decay')\n",
    "parser.add_argument('--start_epoch', type=int, default=0,\n",
    "                    help='resume from the snapshot, and the start_epoch')\n",
    "\n",
    "# Loss specifications\n",
    "parser.add_argument('--loss', type=str, default='1*MSE',\n",
    "                    help='loss function configuration')\n",
    "parser.add_argument('--skip_threshold', type=float, default='1e6',\n",
    "                    help='skipping batch that has large error')\n",
    "\n",
    "\n",
    "# Log specifications\n",
    "parser.add_argument('--save', type=str, default='DTIArbNet',\n",
    "                    help='file name to save')\n",
    "parser.add_argument('--load', type=str, default='.',\n",
    "                    help='file name to load')\n",
    "parser.add_argument('--save_models', action='store_true',\n",
    "                    help='save all intermediate models')\n",
    "parser.add_argument('--resume', type=int, default=0,\n",
    "                    help='resume from specific checkpoint')\n",
    "\n",
    "parser.add_argument('--print_every', type=int, default=200,\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save_every', type=int, default=30,\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "\n",
    "\n",
    "# Hardware specifications\n",
    "# parser.add_argument('--n_threads', type=int, default=2,\n",
    "#                     help='number of threads for data loading')\n",
    "parser.add_argument('--cpu', type=bool, default=False,\n",
    "                    help='use cpu only')\n",
    "# parser.add_argument('--n_GPUs', type=int, default=2,\n",
    "#                     help='number of GPUs')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='random seed')\n",
    "\n",
    "\n",
    "# Training specifications\n",
    "parser.add_argument('--reset', action='store_true',\n",
    "                    help='reset the training')\n",
    "parser.add_argument('--pin_mem', action='store_true',\n",
    "                    help='pin memory for dataloader')\n",
    "parser.add_argument(\"--train_set\", type=float, default=0.7,\n",
    "                    help=\"percentage of data to be used for training\")\n",
    "\n",
    "\n",
    "# Model specifications\n",
    "parser.add_argument('--model', default='dmri_arb',\n",
    "                    help='model name')\n",
    "parser.add_argument('--act', type=str, default='relu',\n",
    "                    help='activation function')\n",
    "parser.add_argument('--pre_train', type=str, default= 'None',\n",
    "                    help='pre-trained model directory')\n",
    "# parser.add_argument('--extend', type=str, default='.',\n",
    "#                     help='pre-trained model directory')\n",
    "# parser.add_argument('--res_scale', type=float, default=1,\n",
    "#                     help='residual scaling')\n",
    "# parser.add_argument('--shift_mean', default=True,\n",
    "#                     help='subtract pixel mean from the input')\n",
    "# parser.add_argument('--dilation', action='store_true',\n",
    "#                     help='use dilated convolution')\n",
    "parser.add_argument('--precision', type=str, default='single',\n",
    "                    choices=('single', 'half'),\n",
    "                    help='FP precision for test (single | half)')\n",
    "args = list(parser.parse_known_args())[0]\n",
    "\n",
    "args.preload = True\n",
    "args.debug = False\n",
    "args.dir = \"/storage\"\n",
    "args.batch_size = 16\n",
    "args.sort = True\n",
    "args.cuda = True\n",
    "args.scale = (1,1,1)\n",
    "args.epochs = 400\n",
    "args.gaps = 20\n",
    "args.offset = 10\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5d83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of common Subjects  171\n",
      "Loading Done\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * MSE\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utility\n",
    "import data\n",
    "import utils\n",
    "import model\n",
    "import loss\n",
    "from trainer import Trainer\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "ids = utils.get_ids()\n",
    "ids.sort()\n",
    "total_vols = 20\n",
    "ids = ids[:total_vols]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(args.seed)\n",
    "    checkpoint = utility.checkpoint(args)       ## setting the log and the train information\n",
    "    if checkpoint.ok:\n",
    "        loader = data.Data(args,ids= ids)                ## data loader\n",
    "        model = model.Model(args, checkpoint)\n",
    "        loss = loss.Loss(args, checkpoint)\n",
    "#         t = Trainer(args, loader, model, loss, checkpoint)\n",
    "#         while not t.terminate():\n",
    "#             t.train()\n",
    "#             t.test()\n",
    "\n",
    "        # checkpoint.done()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346b9897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader.testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c55907",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(loader.testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a311ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([197, 16, 16, 16, 7]) torch.Size([173, 207, 173, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x[0].shape,x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570b08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd7ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "sca = loader.get_scale_test()\n",
    "print(sca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc115ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for iteration, (lr_tensor, hr_tensor,pnts,mask) in enumerate(loader.testing_data, 1):\n",
    "#         pbar.update(1)\n",
    "        if args.cuda:\n",
    "            lr_tensor = lr_tensor.to(device)\n",
    "            hr_tensor = hr_tensor.to(device)\n",
    "            lr_tensor = torch.permute(lr_tensor, (0,4,1,2,3))\n",
    "            with torch.no_grad():\n",
    "                pred_tensor = model(lr_tensor,sca)\n",
    "            \n",
    "        pred_tensor = torch.permute(pred_tensor, (0,2,3,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f919a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
