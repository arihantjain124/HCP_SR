{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06aefe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import rdn\n",
    "import argparse, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3320e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = rdn.make_rdn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7512d24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RDN(\n",
       "  (SFENet1): Conv3d(6, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (SFENet2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (RDBs): ModuleList(\n",
       "    (0-2): 3 x RDB(\n",
       "      (convs): Sequential(\n",
       "        (0): RDB_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): RDB_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): RDB_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (3): RDB_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(112, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (4): RDB_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(144, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (LFF): Conv2d(176, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (GFF): Sequential(\n",
       "    (0): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13287e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.randn(8, 6, 16,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4a9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = enc(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d083af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2a719be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "def _make_pos_encoding(x, size): \n",
    "        B, C, H, W = x.shape\n",
    "        H_up, W_up = size\n",
    "       \n",
    "        h_idx = -1 + 1/H + 2/H * torch.arange(H, device=x.device).float()\n",
    "        w_idx = -1 + 1/W + 2/W * torch.arange(W, device=x.device).float()\n",
    "        in_grid = torch.stack(torch.meshgrid(h_idx, w_idx), dim=0)\n",
    "\n",
    "        h_idx_up = -1 + 1/H_up + 2/H_up * torch.arange(H_up, device=x.device).float()\n",
    "        w_idx_up = -1 + 1/W_up + 2/W_up * torch.arange(W_up, device=x.device).float()\n",
    "        up_grid = torch.stack(torch.meshgrid(h_idx_up, w_idx_up), dim=0)\n",
    "        \n",
    "        rel_grid = (up_grid - F.interpolate(in_grid.unsqueeze(0), size=(H_up, W_up), mode='nearest-exact'))\n",
    "        rel_grid[:,0,:,:] *= H\n",
    "        rel_grid[:,1,:,:] *= W\n",
    "\n",
    "        return rel_grid.contiguous().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "116972ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = out\n",
    "scale = [2,2]\n",
    "B, C, H, W = x.shape\n",
    "H_hr = round(H*scale[0])\n",
    "W_hr = round(W*scale[1])\n",
    "size = [H_hr, W_hr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "560ce905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 64, 64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b32f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_coord = (_make_pos_encoding(x, size).expand(B, -1, *size))\n",
    "ratio = (x.new_tensor([math.sqrt((H*W)/(size[0]*size[1]))]).view(1, -1, 1, 1).expand(B, -1, *size))\n",
    "x = F.interpolate(F.unfold(x, 3, padding=1).view(B, C*9, H, W), size=ratio.shape[-2:], mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a4bb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 128, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_make_pos_encoding(x, size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55325508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 2, 128, 128]),\n",
       " torch.Size([8, 1, 128, 128]),\n",
       " torch.Size([8, 144, 128, 128]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_coord.shape,ratio.shape,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa2c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import dmri_arb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b2705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = dmri_arb.ImplicitDecoder(in_channels=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973c1282",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(144, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Res_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): Res_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): Res_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (3): Res_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (CBAM): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu1): ReLU()\n",
       "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1-4): 4 x Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Res_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): Res_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): Res_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (3): Res_Conv(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (CBAM): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu1): ReLU()\n",
       "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a5aa669",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = [1.2,1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d46de815",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,C,H,W = out.shape\n",
    "size_lr = [H,W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c51a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_hr = round(H*scale[0])\n",
    "W_hr = round(W*scale[1])\n",
    "size=[H_hr,W_hr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "261fc09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = out\n",
    "rel_coord = (dec._make_pos_encoding(out,size).expand(B, -1, *size))\n",
    "ratio = (x.new_tensor([math.sqrt((H*W)/(size[0]*size[1]))]).view(1, -1, 1, 1).expand(B, -1, *size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67be7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 32, 32]),\n",
       " torch.Size([8, 1, 38, 48]),\n",
       " torch.Size([8, 2, 38, 48]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape,ratio.shape,rel_coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d1a1e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 32, 32])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39093a02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImplicitDecoder(\n",
       "  (K): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): ResBlock(\n",
       "        (convs): Sequential(\n",
       "          (0): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (1): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (2): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (3): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CBAM): CBAM(\n",
       "          (ca): ChannelAttention(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "            (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu1): ReLU()\n",
       "            (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (sa): SpatialAttention(\n",
       "            (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1-4): 4 x Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): ResBlock(\n",
       "        (convs): Sequential(\n",
       "          (0): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (1): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (2): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (3): Res_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CBAM): CBAM(\n",
       "          (ca): ChannelAttention(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "            (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu1): ReLU()\n",
       "            (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (sa): SpatialAttention(\n",
       "            (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Q): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): SineAct()\n",
       "    )\n",
       "    (1-4): 4 x Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): SineAct()\n",
       "    )\n",
       "  )\n",
       "  (last_layer): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (ref_branch): Sequential(\n",
       "    (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (in_branch): Sequential(\n",
       "    (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59ec8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DUALRef(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = make_rdn()\n",
    "        self.decoder = ImplicitDecoder()\n",
    "        self.mixer = nn.Conv2d(64*2, 64, 1, padding=0, stride=1)\n",
    "    \n",
    "    def set_scale(self, scale, scale2):\n",
    "        self.scale = scale\n",
    "        self.scale2 = scale2\n",
    "\n",
    "    def forward(self, inp, bsize = None):\n",
    "\n",
    "        B,C,H,W = inp.shape\n",
    "        B,C,H_ref,W_ref = ref.shape\n",
    "        H_hr = round(H*self.scale)\n",
    "        W_hr = round(W*self.scale2)\n",
    "        print(inp.shape)\n",
    "        feat = self.encoder((inp-0.5)/0.5)\n",
    "        with torch.no_grad():\n",
    "            ref = self.encoder((ref-0.5)/0.5)\n",
    "        ref.requires_grad = True\n",
    "        size = [H_hr, W_hr]\n",
    "        pred,pred_ref = self.decoder(feat, ref, size, bsize)\n",
    "\n",
    "        return pred*0.5+0.5, pred_ref*0.5+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e04e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(block_size=(64, 64, 1))\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"DMRI\")\n",
    "parser.add_argument(\"--block_size\", type=tuple, default=(64,64,1),\n",
    "                    help=\"Block Size\")\n",
    "args = list(parser.parse_known_args())[0]\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d43792",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DUALRef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ce377f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DUALRef(\n",
       "  (encoder): RDN(\n",
       "    (SFENet1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (SFENet2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (RDBs): ModuleList(\n",
       "      (0-4): 5 x RDB(\n",
       "        (convs): Sequential(\n",
       "          (0): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (1): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (2): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (3): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (4): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (5): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (6): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (7): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (8): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (9): RDB_Conv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(640, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (LFF): Conv2d(704, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (GFF): Sequential(\n",
       "      (0): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (decoder): ImplicitDecoder(\n",
       "    (K): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): ResBlock(\n",
       "          (convs): Sequential(\n",
       "            (0): Res_Conv(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Res_Conv(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (2): Res_Conv(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (3): Res_Conv(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (CBAM): CBAM(\n",
       "            (ca): ChannelAttention(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "              (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu1): ReLU()\n",
       "              (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (sa): SpatialAttention(\n",
       "              (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-4): 4 x Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): ResBlock(\n",
       "          (convs): Sequential(\n",
       "            (0): Res_Conv(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Res_Conv(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (2): Res_Conv(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (3): Res_Conv(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (CBAM): CBAM(\n",
       "            (ca): ChannelAttention(\n",
       "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "              (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu1): ReLU()\n",
       "              (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (sa): SpatialAttention(\n",
       "              (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Q): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): SineAct()\n",
       "      )\n",
       "      (1-4): 4 x Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): SineAct()\n",
       "      )\n",
       "    )\n",
       "    (last_layer): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ref_branch): Sequential(\n",
       "      (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (in_branch): Sequential(\n",
       "      (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixer): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
